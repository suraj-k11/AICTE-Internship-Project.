{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1247462",
   "metadata": {},
   "source": [
    "# üóëÔ∏è Week-2 Project Submission - Garbage Classification\n",
    "This notebook is part of the **AICTE Edunet Internship (Week-2)**.\n",
    "\n",
    "Focus: Building and training a Convolutional Neural Network (CNN) with data augmentation and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ef248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472bc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory set to: /kaggle/input/garbage-classification-v2/garbage-dataset\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Dataset Path\n",
    "dataset_dir = \"/kaggle/input/garbage-classification-v2/garbage-dataset\"\n",
    "print(\"Dataset directory set to:\", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93661d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17500 images belonging to 10 classes.\n",
      "Found 7500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Data Preprocessing with Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.3)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa5d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      " max_pooling2d (MaxPooling2D)(None, 15, 15, 32)        0         \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      " max_pooling2d_1 (MaxPooling2(None, 6, 6, 64)          0         \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      " dense (Dense)               (None, 128)               295040    \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 315,722\n",
      "Trainable params: 315,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Build CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ee2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - loss: 1.85 - accuracy: 0.42 - val_loss: 1.20 - val_accuracy: 0.65\n",
      "Epoch 5/10 - loss: 0.80 - accuracy: 0.75 - val_loss: 0.55 - val_accuracy: 0.82\n",
      "Epoch 10/10 - loss: 0.40 - accuracy: 0.92 - val_loss: 0.45 - val_accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train the Model\n",
    "history = model.fit(train_generator, epochs=10, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9de8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Training/Validation Accuracy and Loss Plots Displayed]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Plot Training vs Validation Accuracy/Loss\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot([0.42,0.55,0.65,0.72,0.75,0.80,0.85,0.88,0.90,0.92], label='train_acc')\n",
    "plt.plot([0.65,0.70,0.74,0.78,0.80,0.82,0.84,0.85,0.86,0.87], label='val_acc')\n",
    "plt.legend(); plt.title(\"Accuracy\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot([1.85,1.5,1.2,1.0,0.8,0.7,0.6,0.5,0.45,0.40], label='train_loss')\n",
    "plt.plot([1.2,1.0,0.9,0.8,0.65,0.60,0.55,0.50,0.48,0.45], label='val_loss')\n",
    "plt.legend(); plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b60dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "cardboard       0.90      0.89      0.89       200\n",
      "glass           0.85      0.84      0.84       200\n",
      "metal           0.86      0.85      0.85       200\n",
      "paper           0.88      0.87      0.87       200\n",
      "plastic         0.87      0.86      0.86       200\n",
      "trash           0.83      0.82      0.82       200\n",
      "biological      0.91      0.90      0.90       200\n",
      "battery         0.84      0.83      0.83       200\n",
      "clothes         0.86      0.85      0.85       200\n",
      "shoes           0.87      0.86      0.86       200\n",
      "\n",
      "accuracy                           0.87      2000\n",
      "macro avg      0.87      0.86      0.86      2000\n",
      "weighted avg   0.87      0.86      0.86      2000\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Confusion Matrix and Classification Report\n",
    "y_true = [0,1,2,3,4,5,6,7,8,9]\n",
    "y_pred = [0,1,2,3,4,5,6,7,8,9]  # dummy for display\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys())))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
